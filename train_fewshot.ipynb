{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7a0520ec10736f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    " ### Load metadata \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad72bf31-7243-4e0a-8be3-0572e538df9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change paths accordingly\n",
    "# https://github.com/BohemianVRA/DanishFungiDataset/tree/main?tab=readme-ov-file\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "IMAGE_DIR = \"C:/MushroomClassification/Image_classification/Original_datasets_and_codes/datasets/a/Mushroom_DF20/DF20-train_val/DF20\"\n",
    "TRAIN_METADATA_PATH = \"C:/MushroomClassification/Image_classification/Original_datasets_and_codes/datasets/a/Mushroom_DF20\" + \"/DF20-train_metadata_PROD-2.csv\"\n",
    "TEST_METADATA_PATH = \"C:/MushroomClassification/Image_classification/Original_datasets_and_codes/datasets/a/Mushroom_DF20\" + \"/DF20-public_test_metadata_PROD-2.csv\"\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_METADATA_PATH)\n",
    "test_df = pd.read_csv(TEST_METADATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f5672b-07ec-4f93-85a8-5b8cb2c7198b",
   "metadata": {},
   "source": [
    " ### Load metadata (if path changes) - do it once\n",
    "Updating Image Paths for Training Data:\n",
    "\n",
    "This line updates the image_path column in the train_df DataFrame.\n",
    "\n",
    "The .apply() function applies a lambda function to each element in the image_path column.\n",
    "\n",
    "osp.basename(path) extracts the base name of the file from the path (i.e., the file name without any directory information).\n",
    "\n",
    "osp.join(IMAGE_DIR, osp.basename(path)) constructs a new file path by joining the base image directory (IMAGE_DIR) with the base name of the image file. This results in a full path to the image file in the specified directory.\n",
    "\n",
    "The updated paths replace the existing paths in the image_path column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4556a2ae-31b0-4bda-9c4b-c8a8190c23ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"image_path\"] = train_df.image_path.apply(\n",
    "    lambda path: osp.join(IMAGE_DIR, osp.basename(path)))\n",
    "\n",
    "test_df[\"image_path\"] = test_df.image_path.apply(\n",
    "    lambda path: osp.join(IMAGE_DIR, osp.basename(path)))\n",
    "\n",
    "# Save updated metadata\n",
    "updated_train_metadata_path = osp.join(osp.dirname(TRAIN_METADATA_PATH), Path(TRAIN_METADATA_PATH).stem + \"-updated.csv\")\n",
    "updated_test_metadata_path = osp.join(osp.dirname(TEST_METADATA_PATH), Path(TEST_METADATA_PATH).stem + \"-updated.csv\")\n",
    "train_df.to_csv(updated_train_metadata_path, index=False)\n",
    "test_df.to_csv(updated_test_metadata_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d70764-6e0f-44d1-bd6e-782b27d9fcf5",
   "metadata": {},
   "source": [
    "## Trying the inputs and target for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dd05fc-d2c7-40f8-a5ba-793286f73206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map species labels to integer indices\n",
    "species_mapping = {species_name: idx for idx, species_name in enumerate(train_df['species'].unique())}\n",
    "train_df['species2'] = train_df['species'].map(species_mapping)\n",
    "print(\"Class mapping:\", species_mapping)  # To verify the mapping\n",
    "\n",
    "# Determine the number of unique classes\n",
    "num_species = len(species_mapping)\n",
    "print(\"Number of species:\", num_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c13b04-503d-4c5d-ab38-8a4c0fe1d0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map class labels to integer indices\n",
    "class_mapping = {class_name: idx for idx, class_name in enumerate(train_df['class'].unique())}\n",
    "train_df['class'] = train_df['class'].map(class_mapping)\n",
    "print(\"Class mapping:\", class_mapping)  # To verify the mapping\n",
    "\n",
    "# Determine the number of unique classes\n",
    "num_classes = len(class_mapping)\n",
    "print(\"Number of classes:\", num_classes)\n",
    "\n",
    "test_df['class'] = test_df['class'].map(class_mapping)\n",
    "print(\"Class mapping:\", class_mapping)  # To verify the mapping\n",
    "\n",
    "# Determine the number of unique classes\n",
    "num_classes = len(class_mapping)\n",
    "print(\"Number of classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4e6d23-4428-4a09-ae73-2851f9472090",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a784d1-bab6-4eea-8076-6a49d7e7c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoders = {}\n",
    "#columns_to_be_encoded = [\"Habitat\", \"Substrate\", \"species\"]\n",
    "columns_to_be_encoded = [\"species\"]\n",
    "\n",
    "for column_name in columns_to_be_encoded:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    label_encoders = {column_name: le}\n",
    "    \n",
    "    train_df[column_name] = le.fit_transform(train_df[column_name]).astype(np.int64)\n",
    "    test_df[column_name] = le.fit_transform(test_df[column_name]).astype(np.int64)\n",
    "\n",
    "\n",
    "metadata = pd.concat([train_df, test_df])\n",
    "len(metadata)\n",
    "\n",
    "TARGET_FEATURE = \"class_id\"\n",
    "train_df.head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f417f2-6210-445e-af2d-ed7e79991afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06315d64-828f-45c5-9fd4-8e240e71d3af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# File paths (change paths accordingly)\n",
    "IMAGE_DIR = \"G:/MushroomClassification/Image_classification/Original_datasets_and_codes/datasets/a/Mushroom_DF20/DF20-train_val/DF20\"\n",
    "TRAIN_METADATA_PATH = \"G:/MushroomClassification/Image_classification/Original_datasets_and_codes/datasets/a/Mushroom_DF20/DF20-train_metadata_PROD-2-updated.csv\"\n",
    "\n",
    "# Fix image paths by combining with the IMAGE_DIR\n",
    "train_df['image_path'] = train_df['image_path'].apply(lambda x: os.path.join(IMAGE_DIR, x.replace('\\\\', '/')))\n",
    "\n",
    "# Extract features and labels using SELECTED_FEATURES\n",
    "SELECTED_FEATURES = [\"species\"]\n",
    "X = train_df[SELECTED_FEATURES]\n",
    "y = train_df['class_id']  # Adjust if there is a different target column\n",
    "\n",
    "print(X)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d735bfb8-3434-4cab-bf10-8ae6998f4028",
   "metadata": {},
   "source": [
    "## 1) Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a57e427-1619-4796-84dc-5abf046a4d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Suppress DecompressionBombWarning\n",
    "Image.MAX_IMAGE_PIXELS = 150000000 \n",
    "\n",
    "# ================ Data Processing ===========================\n",
    "# File paths (change paths accordingly)\n",
    "IMAGE_DIR = \"C:/MushroomClassification/Image_classification/Original_datasets_and_codes/datasets/a/Mushroom_DF20/DF20-train_val/DF20\"\n",
    "TRAIN_METADATA_PATH = \"C:/MushroomClassification/Image_classification/Original_datasets_and_codes/datasets/a/Mushroom_DF20/DF20-train_metadata_PROD-2-updated.csv\"\n",
    "TEST_METADATA_PATH = \"C:/MushroomClassification/Image_classification/Original_datasets_and_codes/datasets/a/Mushroom_DF20/DF20-public_test_metadata_PROD-2-updated.csv\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load and update metadata\n",
    "train_df = pd.read_csv(TRAIN_METADATA_PATH)\n",
    "train_df[\"image_path\"] = train_df[\"image_path\"].apply(lambda path: os.path.join(IMAGE_DIR, os.path.basename(path)))\n",
    "\n",
    "test_df = pd.read_csv(TEST_METADATA_PATH)\n",
    "test_df[\"image_path\"] = test_df[\"image_path\"].apply(lambda path: os.path.join(IMAGE_DIR, os.path.basename(path)))\n",
    "\n",
    "train_df = train_df.dropna(subset=[\"image_path\", \"class_id\"])\n",
    "test_df = test_df.dropna(subset=[\"image_path\", \"class_id\"])\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(train_df[\"class_id\"])\n",
    "\n",
    "# ================ End of Data Processing ====================\n",
    "\n",
    "# Step 2: Create a Custom Dataset Class\n",
    "class MushroomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define data transformations\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Increased image size for better feature extraction\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create dataset and split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_df['image_path'], y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = MushroomDataset(X_train.tolist(), y_train, transform=data_transforms)\n",
    "val_dataset = MushroomDataset(X_val.tolist(), y_val, transform=data_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Step 3: Define a Simple CNN Model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Step 4: Train the Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN(num_classes=len(np.unique(y_encoded))).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\") as tepoch:\n",
    "        for images, labels in tepoch:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            tepoch.set_postfix(loss=loss.item(), accuracy=100 * correct / total)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "    # Validate the model\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    print(f\"Validation Accuracy after Epoch {epoch + 1}: {val_accuracy:.2f}%\")\n",
    "\n",
    "# Final Evaluation\n",
    "print(f\"Final Validation Accuracy: {val_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ce5c15-003b-4f20-b1dd-8a7300855e20",
   "metadata": {},
   "source": [
    "## 2) EfficientNet_B0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b4f073-5282-43a1-88c3-8642642e7fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Suppress DecompressionBombWarning\n",
    "Image.MAX_IMAGE_PIXELS = 150000000  \n",
    "\n",
    "# File paths\n",
    "IMAGE_DIR = \"C:/MushroomClassification/Image_classification/Original_datasets_and_codes/datasets/a/Mushroom_DF20/DF20-train_val/DF20\"\n",
    "TRAIN_METADATA_PATH = \"C:/MushroomClassification/Image_classification/Original_datasets_and_codes/datasets/a/Mushroom_DF20/DF20-train_metadata_PROD-2-updated.csv\"\n",
    "TEST_METADATA_PATH = \"C:/MushroomClassification/Image_classification/Original_datasets_and_codes/datasets/a/Mushroom_DF20/DF20-public_test_metadata_PROD-2-updated.csv\"\n",
    "\n",
    "\n",
    "\n",
    "# Load and update metadata\n",
    "train_df = pd.read_csv(TRAIN_METADATA_PATH)\n",
    "train_df[\"image_path\"] = train_df[\"image_path\"].apply(lambda path: os.path.join(IMAGE_DIR, os.path.basename(path)))\n",
    "\n",
    "test_df = pd.read_csv(TEST_METADATA_PATH)\n",
    "test_df[\"image_path\"] = test_df[\"image_path\"].apply(lambda path: os.path.join(IMAGE_DIR, os.path.basename(path)))\n",
    "\n",
    "train_df = train_df.dropna(subset=[\"image_path\", \"class_id\"])\n",
    "test_df = test_df.dropna(subset=[\"image_path\", \"class_id\"])\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(train_df[\"class_id\"])\n",
    "\n",
    "# Define dataset class\n",
    "class MushroomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Data augmentation and normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_df['image_path'], y_encoded, test_size=0.2, random_state=42)\n",
    "train_dataset = MushroomDataset(X_train.tolist(), y_train, transform=transform)\n",
    "val_dataset = MushroomDataset(X_val.tolist(), y_val, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Load Efficient-B0\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "num_features = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_features, len(np.unique(y_encoded)))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "num_epochs = 5\n",
    "\n",
    "# File to store metrics\n",
    "log_file = \"training_log_efficieintnetb0.csv\"\n",
    "with open(log_file, \"w\") as f:\n",
    "    f.write(\"epoch,batch,loss,accuracy\\n\")  # CSV header\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\") as tepoch:\n",
    "        for batch_idx, (images, labels) in enumerate(tepoch):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            batch_accuracy = 100 * correct / total\n",
    "            tepoch.set_postfix(loss=loss.item(), accuracy=batch_accuracy)\n",
    "\n",
    "            # Save per-batch metrics\n",
    "            with open(log_file, \"a\") as f:\n",
    "                f.write(f\"{epoch+1},{batch_idx+1},{loss.item():.4f},{batch_accuracy:.2f}\\n\")\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "# Final evaluation\n",
    "model.eval()\n",
    "final_correct = 0\n",
    "final_total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        final_total += labels.size(0)\n",
    "        final_correct += (predicted == labels).sum().item()\n",
    "\n",
    "final_accuracy = 100 * final_correct / final_total\n",
    "print(f\"Final Validation Accuracy: {final_accuracy:.2f}%\")\n",
    "\n",
    "# Load training logs for plotting\n",
    "df = pd.read_csv(log_file)\n",
    "\n",
    "# Plot loss curve\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df[\"batch\"], df[\"loss\"], label=\"Loss\", color=\"red\")\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve per Batch\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot accuracy curve\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df[\"batch\"], df[\"accuracy\"], label=\"Accuracy\", color=\"blue\")\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Accuracy Curve per Batch\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a896fb1-45eb-48c3-ae17-a419589ee5e6",
   "metadata": {},
   "source": [
    "## 3) EfficientViT_B0\n",
    "https://github.com/mit-han-lab/efficientvit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430a713a-4434-432f-9f76-f24b4238b874",
   "metadata": {},
   "source": [
    "-Use Mixed Precision: If you're using PyTorch, enable torch.autocast for faster computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b430a6-7780-43ec-bac7-3d9fe076dc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import timm  # Import timm for EfficientViT\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# Prevent Image Size Warning\n",
    "Image.MAX_IMAGE_PIXELS = 150000000  \n",
    "\n",
    "# File Paths\n",
    "IMAGE_DIR = \"C:/MushroomClassification/Image_classification/Original_datasets_and_codes/datasets/a/Mushroom_DF20/DF20-train_val/DF20\"\n",
    "TRAIN_METADATA_PATH = \"C:/MushroomClassification/Image_classification/Original_datasets_and_codes/datasets/a/Mushroom_DF20/DF20-train_metadata_PROD-2-updated.csv\"\n",
    "TEST_METADATA_PATH = \"C:/MushroomClassification/Image_classification/Original_datasets_and_codes/datasets/a/Mushroom_DF20/DF20-public_test_metadata_PROD-2-updated.csv\"\n",
    "\n",
    "\n",
    "# Load Metadata\n",
    "train_df = pd.read_csv(TRAIN_METADATA_PATH)\n",
    "train_df[\"image_path\"] = train_df[\"image_path\"].apply(lambda path: os.path.join(IMAGE_DIR, os.path.basename(path)))\n",
    "\n",
    "test_df = pd.read_csv(TEST_METADATA_PATH)\n",
    "test_df[\"image_path\"] = test_df[\"image_path\"].apply(lambda path: os.path.join(IMAGE_DIR, os.path.basename(path)))\n",
    "\n",
    "# Drop Missing Values\n",
    "train_df = train_df.dropna(subset=[\"image_path\", \"class_id\"])\n",
    "test_df = test_df.dropna(subset=[\"image_path\", \"class_id\"])\n",
    "\n",
    "# Encode Labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(train_df[\"class_id\"])\n",
    "\n",
    "# Custom Dataset Class\n",
    "class MushroomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with Image.open(self.image_paths[idx]) as img:\n",
    "            img.thumbnail((1000, 1000))  # Reduce size to prevent memory issues\n",
    "            img = img.convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# Data Augmentation & Normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Train-Validation Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_df['image_path'], y_encoded, test_size=0.2, random_state=42)\n",
    "train_dataset = MushroomDataset(X_train.tolist(), y_train, transform=transform)\n",
    "val_dataset = MushroomDataset(X_val.tolist(), y_val, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load EfficientViT-B0 Model\n",
    "model = timm.create_model(\"efficientvit_b0\", pretrained=True)\n",
    "num_classes = len(np.unique(y_encoded))\n",
    "model.reset_classifier(num_classes=num_classes)\n",
    "\n",
    "# ðŸš€ Use GPU if available, otherwise fallback to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define Loss Function & Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 5\n",
    "\n",
    "# Training Loop\n",
    "train_results = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\") as tepoch:\n",
    "        for images, labels in tepoch:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            tepoch.set_postfix(loss=loss.item(), accuracy=100 * correct / total)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    train_results.append([epoch + 1, epoch_loss, epoch_acc])\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "\n",
    "# Save Training Results\n",
    "train_results_df = pd.DataFrame(train_results, columns=[\"Epoch\", \"Loss\", \"Accuracy\"])\n",
    "train_results_df.to_csv(\"training_results_efficientvitb0.csv\", index=False)\n",
    "\n",
    "# Final Evaluation\n",
    "model.eval()\n",
    "final_correct = 0\n",
    "final_total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        final_total += labels.size(0)\n",
    "        final_correct += (predicted == labels).sum().item()\n",
    "\n",
    "final_accuracy = 100 * final_correct / final_total\n",
    "print(f\"Final Validation Accuracy: {final_accuracy:.2f}%\")\n",
    "\n",
    "# Save Final Accuracy\n",
    "with open(\"final_accuracy.txt\", \"w\") as f:\n",
    "    f.write(f\"Final Validation Accuracy: {final_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978b216e-3c9d-42f7-be13-0d8ffb25183b",
   "metadata": {},
   "source": [
    "## 4) Few-Shot Learning  -GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330af84e-a225-48a4-9759-efd62575b625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Ensure the device is specified with an index\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "# Set memory fraction for the specified GPU\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_per_process_memory_fraction(0.99, device=device.index)\n",
    "print(f\"Memory Allocated: {torch.cuda.memory_allocated(device) / 1e6:.2f} MB\")\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Device:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "\n",
    "print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    for i in range(num_gpus):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"No GPUs available.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0893b-f524-4dfc-a410-57ba357f81ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move an existing tensor to GPU\n",
    "tensor_cpu = torch.randn(10, 10)\n",
    "tensor_gpu = tensor_cpu.to(device)\n",
    "print(tensor_gpu.device)  # Output should be: cuda:0\n",
    "\n",
    "print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a200765c-cbd6-4a02-98ad-5f6287e62142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import timm\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prevent Image Size Warning\n",
    "Image.MAX_IMAGE_PIXELS = 150000000\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# File Paths\n",
    "IMAGE_DIR = \"C:/MushroomClassification/Image_classification/Original_datasets_and_codes/datasets/a/Mushroom_DF20/DF20-train_val/DF20\"\n",
    "TRAIN_METADATA_PATH = \"C:/MushroomClassification/Image_classification/Original_datasets_and_codes/datasets/a/Mushroom_DF20/DF20-train_metadata_PROD-2-updated.csv\"\n",
    "TEST_METADATA_PATH = \"C:/MushroomClassification/Image_classification/Original_datasets_and_codes/datasets/a/Mushroom_DF20/DF20-public_test_metadata_PROD-2-updated.csv\"\n",
    "\n",
    "\n",
    "# Load Metadata\n",
    "train_df = pd.read_csv(TRAIN_METADATA_PATH)\n",
    "train_df[\"image_path\"] = train_df[\"image_path\"].apply(lambda path: os.path.join(IMAGE_DIR, os.path.basename(path)))\n",
    "\n",
    "test_df = pd.read_csv(TEST_METADATA_PATH)\n",
    "test_df[\"image_path\"] = test_df[\"image_path\"].apply(lambda path: os.path.join(IMAGE_DIR, os.path.basename(path)))\n",
    "\n",
    "# Drop Missing Values\n",
    "train_df = train_df.dropna(subset=[\"image_path\", \"class_id\"])\n",
    "test_df = test_df.dropna(subset=[\"image_path\", \"class_id\"])\n",
    "\n",
    "# Encode Labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(train_df[\"class_id\"])\n",
    "\n",
    "# Custom Dataset Class\n",
    "class MushroomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with Image.open(self.image_paths[idx]) as img:\n",
    "            img.thumbnail((1000, 1000))  # Reduce size to prevent memory issues\n",
    "            img = img.convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# Data Augmentation & Normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Train-Validation Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_df['image_path'], y_encoded, test_size=0.2, random_state=42)\n",
    "train_dataset = MushroomDataset(X_train.tolist(), y_train, transform=transform)\n",
    "val_dataset = MushroomDataset(X_val.tolist(), y_val, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Prototypical Network\n",
    "class PrototypicalNetwork(nn.Module):\n",
    "    def __init__(self, feature_extractor):\n",
    "        super(PrototypicalNetwork, self).__init__()\n",
    "        self.feature_extractor = feature_extractor\n",
    "\n",
    "    def forward(self, support, query, n_way, k_shot):\n",
    "        # Extract features for support and query\n",
    "        support_features = self.feature_extractor(support)  # Shape: [n_way * k_shot, feature_dim]\n",
    "        query_features = self.feature_extractor(query)      # Shape: [query_size, feature_dim]\n",
    "\n",
    "        # Reshape support features to [n_way, k_shot, feature_dim]\n",
    "        support_features = support_features.view(n_way, k_shot, -1).mean(dim=1)  # Shape: [n_way, feature_dim]\n",
    "\n",
    "        # Compute distances\n",
    "        dists = torch.cdist(query_features, support_features)  # Shape: [query_size, n_way]\n",
    "        return -dists  # Negative distances as logits\n",
    "\n",
    "# Load EfficientViT-B0 Feature Extractor\n",
    "feature_extractor = timm.create_model(\"efficientvit_b0\", pretrained=True, num_classes=0)  # No classifier\n",
    "\n",
    "# Utilize GPU if available\n",
    "feature_extractor = feature_extractor.to(device)\n",
    "\n",
    "# Initialize Prototypical Network\n",
    "model = PrototypicalNetwork(feature_extractor).to(device)\n",
    "\n",
    "# Few-shot Training Parameters\n",
    "n_way = 5\n",
    "k_shot = 5\n",
    "q_query = 5\n",
    "n_epochs = 10\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Few-shot Training and Validation\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{n_epochs}\", unit=\"batch\") as tepoch:\n",
    "        for images, labels in tepoch:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Prepare support and query sets\n",
    "            support_idx = torch.randperm(images.size(0))[:n_way * k_shot]\n",
    "            query_idx = torch.randperm(images.size(0))[n_way * k_shot:n_way * k_shot + q_query]\n",
    "\n",
    "            support = images[support_idx]\n",
    "            query = images[query_idx]\n",
    "            support_labels = labels[support_idx]\n",
    "            query_labels = labels[query_idx]\n",
    "\n",
    "            # Map support labels to prototype indices\n",
    "            unique_labels = torch.unique(support_labels)\n",
    "            if len(unique_labels) < n_way:\n",
    "                continue  # Skip if not enough classes in the support set\n",
    "\n",
    "            label_map = {label.item(): i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "            # Remap support labels\n",
    "            support_labels = torch.tensor([label_map[label.item()] for label in support_labels]).to(device)\n",
    "\n",
    "            # Filter and remap query labels\n",
    "            valid_query_indices = [i for i, label in enumerate(query_labels) if label.item() in label_map]\n",
    "            if len(valid_query_indices) == 0:\n",
    "                continue  # Skip if no valid queries are available\n",
    "            query = query[valid_query_indices]\n",
    "            query_labels = query_labels[valid_query_indices]\n",
    "            query_labels = torch.tensor([label_map[label.item()] for label in query_labels]).to(device)\n",
    "\n",
    "            # Verify label compatibility with logits\n",
    "            if query_labels.max() >= n_way:\n",
    "                continue  # Skip if remapped query labels exceed n_way - 1\n",
    "\n",
    "            # Forward and Backward Pass\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(support, query, n_way, k_shot)  # Logits shape: [q_query, n_way]\n",
    "            loss = F.cross_entropy(logits, query_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate batch accuracy\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            correct += (predicted == query_labels).sum().item()\n",
    "            total += query_labels.size(0)\n",
    "\n",
    "            # Update tqdm progress bar\n",
    "            tepoch.set_postfix(loss=loss.item(), accuracy=100 * correct / total)\n",
    "\n",
    "    print(f\"Memory Allocated: {torch.cuda.memory_allocated(device) / 1e6:.2f} MB\")\n",
    "\n",
    "\n",
    "# Save the Model\n",
    "torch.save(model.state_dict(), \"fewshot_train_valid_gpu.pth\")\n",
    "\n",
    "# Plot Loss and Accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, n_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, n_epochs + 1), val_losses, label='Validation Loss')\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot Validation Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, n_epochs + 1), val_accuracies, label='Validation Accuracy')\n",
    "plt.plot(range(1, n_epochs + 1), train_accuracies, label='Validation Accuracy')\n",
    "plt.title(\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch3",
   "language": "python",
   "name": "torch3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
